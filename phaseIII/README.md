
Saved

Hide assistant
# Phase III: Prototypes and User Testing



## Introduction



Phase III's sole purpose was to test the Rosetta Song prototype with a user test. By conducting user tests, our team aims to identify user preferences, find problematic aspects of the prototype, and note opportunities for improvement in the prototype's design and functionality.

## Protocol

[Protocol](../phaseIII/x18_Draft_protocol.pdf)

## Methods

Our team utilized all our planning to conduct the user testing of our prototype. This included our introduction, in which we explained to the tester the atmosphere of the test, how the test’s information would be kept, and how we would like the tester to behave during the testing. Next, we wanted some background information on each subject so we gathered information that was non-specific to the participants. Reference the Draft protocol for specific questions. The goal of the initial questions was to establish how possibly useful our product would be but also if the participants had any general interest in the problem our product is meant to solve. After we gathered some basic information about our participants' backgrounds we moved on to conducting our first task. In this task we had the user demonstrate how they would act if they were to run into an error on our site. The goal of this task was to understand if our system’s error response is easy and understandable. The next task had the participants updating information on the profile page. The purpose of this task was to see how the user navigated the site and if the user could get to the correct pages. For the third task, our team had our participants attempt to find relevant information to their account. The purpose of this task was to make sure that the stats that our site renders are not only useful but wanted. Reference the draft protocol for any specific language. Finally, we had our participants conduct a simple transfer of music from one service to another. This was to test the main functionality of the website and see if the user could understand our conventions. Following the completion of the task each participant was asked about their experience with ease of use. This was a scale of 1 to 5, 5 being very easy and 1 being very hard. The time was also noted to gather information about user timing to complete and ease of task. After finishing the tasks each participant was asked a series of questions to debrief the subject from the experience they had. These questions included topics like what the participant enjoyed and did not enjoy, if the error messages were understandable and dealt with the issue correctly, what kind of things could be optimized inside the tasks, and more. Reference the draft protocol for any specific questions. The purpose of these questions were to find out if the participants had any more information about their experience and how we could improve. To close the test we thanked the participants and dismissed them.



## Findings



### Background

Every participant had experience with at least two music streaming services before the user study.  A vast majority of them (6/7 participants) had friends or family who used a different streaming service and would be interested in sharing music with them. Every participant said that they would want to try alternative streaming services if it was seamless to change between them.



### Test results

All of our tests had extremely high ratings from the participants in terms of satisfaction (m > 4.5/5) except for our task 1, (m = 3.86/5, sd = 1.35). When taking an average of all task ratings, the average came out to (m = 4.5/5) across all tasks, and the (sd = .903). 



Task 1 and task 3 were the only tasks to specifically be given criticism in the debrief, but task 1 was much more so. A majority of participants either listed their least favorite part of the experience as the "transfer cart" or the "profile section". Task 1 also had (m = 3.86, sd = 1.35), and had by far the most amount of variation in scores. Task 3 had (m = 4.57, sd = 1.13) which alos had a large variation which had the second highest standard deviation.

Tasks 2 had (m = 4.71, sd = 0.756) and task 4 had (m = 8.56, sd = 0.378) giving them both very high satisfaction.



### Duration

Every task was completed in under 5 minutes, and many participants completed tasks in under 1 minute, making (m < 3) minutes per task. Every task was completed by every participant, except for one time in task 1, and one time in task 3, who were then given a hint and were able to complete the task (still marked as failure).



## Conclusions



As shown by our data, task 1 appeared to be the most challenging for the participants. This task requires the participant to use the main feature of our product, the playlist transferer. One participant seemed to get lost through the menus, eventually looping back and repeating a cycle that did not make progress toward the task. The two main points we took away from that task were the misunderstandings of the word "cart" and the possibility of having too many buttons. We observed several instances of participants clicking on buttons aimlessly, seemingly as a last resort to figure out the task. This could be due to that "over-abundance" of buttons, many of which were not functional yet. We saw this in our transfer cart with the minus buttons, as participants were clicking on these unprogrammed buttons to try and remove a playlist from the cart. Another area that may have been too busy with buttons was the post-login home page. There are probably at least 15 playlists on this page that all have different buttons, as well as the other that surround them. We observed participants getting distracted and clicking some of them at random.



Overall though, our findings show that the most common concern from participants was the ambiguity of the  "transfer cart" idea. In our prototype, the transfer cart is displayed as a small button at the top that says "cart". Some participants noted that it led them to believe they were purchasing something, and was the reason they did not click on it during the tasks. Looking back this makes sense, as it is a common convention for a cart to be related to purchasing. To follow up on that, we have pondered alternatives such as labeling the button "transfer cart" instead of just "cart". Additionally, dropping the "cart" entirely would resolve this issue. Issues with the profile button were less mentioned but were still addressed. One concern was that it was easy to miss and the participant suggested adding the name to the profile button. We thought this was a good idea as it would reinforce and draw attention to that aspect.



## Caveats



All participants of the study are college-aged usability students, so they potentially may have interacted with the prototype differently than a random subset of participants would have. Each participant took part in multiple user tests, so the later participants may have been fatigued from the previous studies. The Rosetta Song study had seven participants, so the impact of a small sample size could have affected the results of the study.
